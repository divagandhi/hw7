{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install otter-grader"
      ],
      "metadata": {
        "id": "yfJ3dcaKnkbd",
        "outputId": "4fd84470-099b-46b0-991c-e8b563c89c8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yfJ3dcaKnkbd",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: otter-grader in /usr/local/lib/python3.12/dist-packages (6.1.6)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from otter-grader) (8.3.0)\n",
            "Requirement already satisfied: dill>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from otter-grader) (0.3.8)\n",
            "Requirement already satisfied: fica>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from otter-grader) (0.4.1)\n",
            "Requirement already satisfied: ipylab<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from otter-grader) (1.1.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from otter-grader) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets<9.0.0,>=8.1.5 in /usr/local/lib/python3.12/dist-packages (from otter-grader) (8.1.8)\n",
            "Requirement already satisfied: jinja2<4.0,>=3.1 in /usr/local/lib/python3.12/dist-packages (from otter-grader) (3.1.6)\n",
            "Requirement already satisfied: jupytext<2.0.0,>=1.16.4 in /usr/local/lib/python3.12/dist-packages (from otter-grader) (1.17.3)\n",
            "Requirement already satisfied: nbconvert>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from otter-grader) (5.10.4)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from otter-grader) (2.2.2)\n",
            "Requirement already satisfied: python-on-whales<1.0.0,>=0.72.0 in /usr/local/lib/python3.12/dist-packages (from otter-grader) (0.79.0)\n",
            "Requirement already satisfied: pyyaml<7,>=6 in /usr/local/lib/python3.12/dist-packages (from otter-grader) (6.0.3)\n",
            "Requirement already satisfied: requests<3.0,>=2.31 in /usr/local/lib/python3.12/dist-packages (from otter-grader) (2.32.4)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from otter-grader) (1.17.3)\n",
            "Requirement already satisfied: docutils in /usr/local/lib/python3.12/dist-packages (from fica>=0.4.1->otter-grader) (0.21.2)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.12/dist-packages (from fica>=0.4.1->otter-grader) (8.2.3)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader) (0.2.3)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.12/dist-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader) (4.0.15)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.12/dist-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader) (3.0.16)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython->otter-grader) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython->otter-grader) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython->otter-grader) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->otter-grader) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->otter-grader) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython->otter-grader) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->otter-grader) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython->otter-grader) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->otter-grader) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0,>=3.1->otter-grader) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=1.0 in /usr/local/lib/python3.12/dist-packages (from jupytext<2.0.0,>=1.16.4->otter-grader) (4.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.12/dist-packages (from jupytext<2.0.0,>=1.16.4->otter-grader) (0.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from jupytext<2.0.0,>=1.16.4->otter-grader) (25.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (0.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (5.9.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (1.5.1)\n",
            "Requirement already satisfied: playwright in /usr/local/lib/python3.12/dist-packages (from nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (1.56.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.0.0->otter-grader) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.0.0->otter-grader) (4.25.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->otter-grader) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->otter-grader) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->otter-grader) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->otter-grader) (2025.2)\n",
            "Requirement already satisfied: pydantic!=2.0.*,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from python-on-whales<1.0.0,>=0.72.0->otter-grader) (2.11.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from python-on-whales<1.0.0,>=0.72.0->otter-grader) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.31->otter-grader) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.31->otter-grader) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.31->otter-grader) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.31->otter-grader) (2025.10.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (1.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->otter-grader) (0.8.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader) (0.28.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.7->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (4.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=1.0->jupytext<2.0.0,>=1.16.4->otter-grader) (0.1.2)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (7.4.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->otter-grader) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->otter-grader) (0.2.14)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0.0,>=0.72.0->otter-grader) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0.0,>=0.72.0->otter-grader) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0.0,>=0.72.0->otter-grader) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->otter-grader) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (2.8)\n",
            "Requirement already satisfied: pyee<14,>=13 in /usr/local/lib/python3.12/dist-packages (from playwright->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (13.0.0)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.12/dist-packages (from playwright->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (3.2.4)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.4.1->otter-grader) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.4.1->otter-grader) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.4.1->otter-grader) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.4.1->otter-grader) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.4.1->otter-grader) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.4.1->otter-grader) (2.0.0)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.4.1->otter-grader) (3.0.1)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.4.1->otter-grader) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.4.1->otter-grader) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.4.1->otter-grader) (1.4.1)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from sphinx->fica>=0.4.1->otter-grader) (3.1.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (0.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (1.6.0)\n",
            "Requirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (6.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1a26ac87",
      "metadata": {
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "1a26ac87",
        "outputId": "279198fd-b380-41d5-bd9d-442679daa4d3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Tests directory ./tests does not exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4279969887.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialize Otter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0motter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgrader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0motter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hw7.ipynb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/otter/check/utils.py\u001b[0m in \u001b[0;36mevent_logger\u001b[0;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/otter/check/utils.py\u001b[0m in \u001b[0;36mevent_logger\u001b[0;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \"\"\"\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLoggedEventReturnValue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/otter/check/notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nb_path, tests_dir, tests_url_prefix)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpreter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mIPythonInterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLAB\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtests_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Tests directory {tests_dir} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Tests directory ./tests does not exist"
          ]
        }
      ],
      "source": [
        "# Initialize Otter\n",
        "import otter\n",
        "grader = otter.Notebook(\"hw7.ipynb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50eca5e1-717f-451f-b23f-ef411de8576f",
      "metadata": {
        "id": "50eca5e1-717f-451f-b23f-ef411de8576f"
      },
      "source": [
        "# CPSC 330 - Applied Machine Learning\n",
        "\n",
        "## Homework 7: Word embeddings and topic modeling\n",
        "**Due date: See the [Calendar](https://htmlpreview.github.io/?https://github.com/UBC-CS/cpsc330/blob/master/docs/calendar.html).**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8f5cb55-0576-4596-ba0e-88d0ad7c39f1",
      "metadata": {
        "id": "a8f5cb55-0576-4596-ba0e-88d0ad7c39f1"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a4651888-484b-42a0-95e1-d273e5069205",
      "metadata": {
        "id": "a4651888-484b-42a0-95e1-d273e5069205"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline, make_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9b799e3-3d4e-4151-9123-9d3733a63ac3",
      "metadata": {
        "id": "f9b799e3-3d4e-4151-9123-9d3733a63ac3"
      },
      "source": [
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b471420d-3bc0-459f-b438-c77e4b3c04a0",
      "metadata": {
        "deletable": false,
        "editable": false,
        "tags": [],
        "id": "b471420d-3bc0-459f-b438-c77e4b3c04a0"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "    \n",
        "## Instructions\n",
        "rubric={points}\n",
        "\n",
        "You will earn points for following these instructions and successfully submitting your work on Gradescope.  \n",
        "\n",
        "### Group wotk instructions\n",
        "\n",
        "**You may work with a partner on this homework and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
        "- The maximum group size is 2.\n",
        "  \n",
        "- Use group work as an opportunity to collaborate and learn new things from each other.\n",
        "- Be respectful to each other and make sure you understand all the concepts in the assignment well.\n",
        "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline.\n",
        "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members).\n",
        "- If you would like to use late tokens for the homework, all group members must have the necessary late tokens available. Please note that the late tokens will be counted for all members of the group.   \n",
        "\n",
        "\n",
        "### General submission instructions\n",
        "\n",
        "- Please **read carefully\n",
        "[Use of Generative AI policy](https://ubc-cs.github.io/cpsc330-2025W1/syllabus.html#use-of-generative-ai-in-the-course)** before starting the homework assignment.\n",
        "- **Run all cells before submitting:** Go to `Kernel -> Restart Kernel and Clear All Outputs`, then select `Run -> Run All Cells`. This ensures your notebook runs cleanly from start to finish without errors.\n",
        "  \n",
        "- **Submit your files on Gradescope.**  \n",
        "   - Upload only your `.ipynb` file **with outputs displayed** and any required output files.\n",
        "     \n",
        "   - Do **not** submit other files from your repository.  \n",
        "   - If you need help, see the [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/).  \n",
        "- **Check that outputs render properly.**  \n",
        "   - Make sure all plots and outputs appear in your submission.\n",
        "     \n",
        "   - If your `.ipynb` file is too large and doesn't render on Gradescope, also upload a PDF or HTML version so the TAs can view your work.  \n",
        "- **Keep execution order clean.**  \n",
        "   - Execution numbers must start at \"1\" and increase in order.\n",
        "     \n",
        "   - Notebooks without visible outputs may not be graded.  \n",
        "   - Out-of-order or missing execution numbers may result in mark deductions.  \n",
        "- **Follow course submission guidelines:** Review the [CPSC 330 homework instructions](https://ubc-cs.github.io/cpsc330-2025W1/docs/homework_instructions.html) for detailed guidance on completing and submitting assignments.\n",
        "   \n",
        "</div>\n",
        "\n",
        "_Points:_ 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69be5b2d-1854-4c63-bcc6-9b6258b7293a",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "69be5b2d-1854-4c63-bcc6-9b6258b7293a"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "859b3f00-a3e5-45d8-b504-22a84ace38cd",
      "metadata": {
        "id": "859b3f00-a3e5-45d8-b504-22a84ace38cd"
      },
      "source": [
        "## Exercise 1:  Exploring pre-trained word embeddings <a name=\"1\"></a>\n",
        "<hr>\n",
        "\n",
        "In lecture 18, we talked about natural language processing (NLP). Using pre-trained word embeddings is very common in NLP. It has been shown that pre-trained word embeddings work well on a variety of text classification tasks. These embeddings are created by training a model like Word2Vec on a huge corpus of text such as a dump of Wikipedia or a dump of the web crawl.\n",
        "\n",
        "A number of pre-trained word embeddings are available out there. Some popular ones are:\n",
        "\n",
        "- [GloVe](https://nlp.stanford.edu/projects/glove/)\n",
        "    * trained using [the GloVe algorithm](https://nlp.stanford.edu/pubs/glove.pdf)\n",
        "    * published by Stanford University\n",
        "- [fastText pre-trained embeddings for 294 languages](https://fasttext.cc/docs/en/pretrained-vectors.html)\n",
        "    * trained using the fastText algorithm\n",
        "    * published by Facebook\n",
        "    \n",
        "In this exercise, you will be exploring GloVe Wikipedia pre-trained embeddings. The code below loads the word vectors trained on Wikipedia using an algorithm called Glove. You'll need `gensim` package in your cpsc330 conda environment to run the code below.\n",
        "\n",
        "```\n",
        "> conda activate cpsc330\n",
        "> conda install -c anaconda gensim\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kByI7KZFUJHl",
        "outputId": "b22acf54-725a-4af9-dff7-211c1eae5aa2"
      },
      "id": "kByI7KZFUJHl",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b4823523-ca44-48a3-94bb-f6e453d27f1c",
      "metadata": {
        "metadata": {
          "tags": [
            "otter_ignore"
          ]
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4823523-ca44-48a3-94bb-f6e453d27f1c",
        "outputId": "0071626d-0d4a-4774-b91c-8c2fb947e85f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "import gensim.downloader\n",
        "\n",
        "print(list(gensim.downloader.info()[\"models\"].keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "83e4717e-215b-4c1b-b08a-9f5adbb52467",
      "metadata": {
        "metadata": {
          "tags": [
            "otter_ignore"
          ]
        },
        "id": "83e4717e-215b-4c1b-b08a-9f5adbb52467"
      },
      "outputs": [],
      "source": [
        "# This will take a while to run when you run it for the first time.\n",
        "import gensim.downloader as api\n",
        "\n",
        "glove_wiki_vectors = api.load(\"glove-wiki-gigaword-100\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "76ec38c4-ce89-4372-b015-035f4d682132",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76ec38c4-ce89-4372-b015-035f4d682132",
        "outputId": "ada836ed-1950-46f6-b35f-9c1534b582df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(glove_wiki_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c78dafb-f712-447a-b870-1fac6c249e5f",
      "metadata": {
        "id": "8c78dafb-f712-447a-b870-1fac6c249e5f"
      },
      "source": [
        "There are 400,000 word vectors in this pre-trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11ea1002-2451-4008-aa83-54618c757bb3",
      "metadata": {
        "id": "11ea1002-2451-4008-aa83-54618c757bb3"
      },
      "source": [
        "Now that we have GloVe Wiki vectors loaded in `glove_wiki_vectors`, let's explore the embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce2a75ac-fd18-4a53-89d3-26f1051c4ef3",
      "metadata": {
        "id": "ce2a75ac-fd18-4a53-89d3-26f1051c4ef3"
      },
      "source": [
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8119fb78-d2be-4ccf-8c8d-31026563e072",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "8119fb78-d2be-4ccf-8c8d-31026563e072"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "### 1.1 Word similarity using pre-trained embeddings\n",
        "rubric={points}\n",
        "\n",
        "**Your tasks:**\n",
        "\n",
        "- Come up with a list of 4 words of your choice and find similar words to these words using `glove_wiki_vectors` embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "787fe4d0-4206-4747-9638-7782cca51d3f",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "787fe4d0-4206-4747-9638-7782cca51d3f"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "\n",
        "Solution_1.1\n",
        "    \n",
        "</div>\n",
        "\n",
        "_Points:_ 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6205ebad-49a9-435a-bf84-ae57d29c2068",
      "metadata": {
        "metadata": {
          "tags": [
            "otter_ignore"
          ]
        },
        "tags": [
          "otter_answer_cell"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6205ebad-49a9-435a-bf84-ae57d29c2068",
        "outputId": "e8f0c4a9-d9c3-468c-eb52-9925016e1f30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 4 words of my choice are: light, plant, laptop, phone\n"
          ]
        }
      ],
      "source": [
        "print('The 4 words of my choice are: light, plant, laptop, phone')\n",
        "words = ['light', 'plant', 'laptop', 'phone']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d59251b0-12c0-41cf-867b-3e5cb90f4d8d",
      "metadata": {
        "metadata": {
          "tags": [
            "otter_ignore"
          ]
        },
        "tags": [
          "otter_answer_cell"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d59251b0-12c0-41cf-867b-3e5cb90f4d8d",
        "outputId": "7d745a3d-1be4-48b3-f038-cf08660a26b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "light\n",
            "  dark\n",
            "  bright\n",
            "  lights\n",
            "  air\n",
            "  blue\n",
            "  visible\n",
            "  color\n",
            "  sky\n",
            "  heavy\n",
            "  water\n",
            "plant\n",
            "  plants\n",
            "  factory\n",
            "  farm\n",
            "  facility\n",
            "  production\n",
            "  produce\n",
            "  processing\n",
            "  fertilizer\n",
            "  waste\n",
            "  factories\n",
            "laptop\n",
            "  laptops\n",
            "  computers\n",
            "  phones\n",
            "  portable\n",
            "  desktop\n",
            "  ipod\n",
            "  computer\n",
            "  handheld\n",
            "  pc\n",
            "  cellphones\n",
            "phone\n",
            "  telephone\n",
            "  cellphone\n",
            "  phones\n",
            "  mobile\n",
            "  mail\n",
            "  internet\n",
            "  messages\n",
            "  wireless\n",
            "  telephones\n",
            "  cellular\n"
          ]
        }
      ],
      "source": [
        "for word in words:\n",
        "  print(word)\n",
        "  for similar, score in glove_wiki_vectors.most_similar(word, topn=10):\n",
        "        print(f\"  {similar}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "23a9bd11-2a14-44f5-8093-b0a696324ce1",
      "metadata": {
        "metadata": {
          "tags": [
            "otter_ignore"
          ]
        },
        "tags": [
          "otter_answer_cell"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23a9bd11-2a14-44f5-8093-b0a696324ce1",
        "outputId": "264ddb7d-3e3f-4d50-b39b-62684129e786"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0b922b29-e591-41a7-b82c-9bcc794d0f10",
      "metadata": {
        "metadata": {
          "tags": [
            "otter_ignore"
          ]
        },
        "tags": [
          "otter_answer_cell"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b922b29-e591-41a7-b82c-9bcc794d0f10",
        "outputId": "2a9b301c-1af3-470a-85ab-1b0c0730a43d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1caa0fc7-900a-4ef5-817f-166cafc8cd27",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1caa0fc7-900a-4ef5-817f-166cafc8cd27",
        "outputId": "b874e014-e222-434b-d4ca-fc779b3a1e18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24714da4-3ee5-424e-9a21-bd4b33de2e08",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "24714da4-3ee5-424e-9a21-bd4b33de2e08"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6461c1d5-42ff-4267-bf04-e3642c5b40bb",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "6461c1d5-42ff-4267-bf04-e3642c5b40bb"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "### 1.2 Word similarity using pre-trained embeddings\n",
        "rubric={points}\n",
        "\n",
        "**Your tasks:**\n",
        "\n",
        "1. Calculate cosine similarity for the following word pairs (`word_pairs`) using the [`similarity`](https://radimrehurek.com/gensim/models/keyedvectors.html?highlight=similarity#gensim.models.keyedvectors.KeyedVectors.similarity) method of `glove_wiki_vectors`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6b37d06f-81c7-4120-8dc7-2270105d5ecb",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "6b37d06f-81c7-4120-8dc7-2270105d5ecb"
      },
      "outputs": [],
      "source": [
        "word_pairs = [\n",
        "    (\"coast\", \"shore\"),\n",
        "    (\"clothes\", \"closet\"),\n",
        "    (\"old\", \"new\"),\n",
        "    (\"smart\", \"intelligent\"),\n",
        "    (\"dog\", \"cat\"),\n",
        "    (\"tree\", \"lawyer\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77427682-97e3-4fa2-b2d6-84940fce9e27",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "77427682-97e3-4fa2-b2d6-84940fce9e27"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "\n",
        "Solution_1.2\n",
        "    \n",
        "</div>\n",
        "\n",
        "_Points:_ 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c7c8c6c4-7113-4cb2-98f8-d34ec1c632e7",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7c8c6c4-7113-4cb2-98f8-d34ec1c632e7",
        "outputId": "362ce9d7-1283-4fde-9761-a4fe5610e42d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity(coast, shore) = 0.7000\n",
            "Similarity(clothes, closet) = 0.5463\n",
            "Similarity(old, new) = 0.6432\n",
            "Similarity(smart, intelligent) = 0.7553\n",
            "Similarity(dog, cat) = 0.8798\n",
            "Similarity(tree, lawyer) = 0.0767\n"
          ]
        }
      ],
      "source": [
        "for word1, word2 in word_pairs:\n",
        "    sim = glove_wiki_vectors.similarity(word1, word2)\n",
        "    print(f\"Similarity({word1}, {word2}) = {sim:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f1a6420-ae43-4469-99e1-59a966238a43",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "2f1a6420-ae43-4469-99e1-59a966238a43"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77d9186e-ab44-43e5-8a96-7a1c4130b598",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "77d9186e-ab44-43e5-8a96-7a1c4130b598"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "### 1.3 Representation of all words in English\n",
        "rubric={points}\n",
        "\n",
        "**Your tasks:**\n",
        "\n",
        "1. The vocabulary size of Wikipedia embeddings is quite large. The `test_words` list below contains a few new words (called neologisms) and biomedical domain-specific abbreviations. Write code to check whether `glove_wiki_vectors` have representation for these words or not.\n",
        "> If a given word `word` is in the vocabulary, `word in glove_wiki_vectors` will return True."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "be6a6488-5139-43cb-a88c-b1d45df700cf",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "be6a6488-5139-43cb-a88c-b1d45df700cf"
      },
      "outputs": [],
      "source": [
        "test_words = [\n",
        "    \"covididiot\",\n",
        "    \"fomo\",\n",
        "    \"frenemies\",\n",
        "    \"anthropause\",\n",
        "    \"photobomb\",\n",
        "    \"selfie\",\n",
        "    \"pxg\",  # Abbreviation for pseudoexfoliative glaucoma\n",
        "    \"pacg\",  # Abbreviation for primary angle closure glaucoma\n",
        "    \"cct\",  # Abbreviation for central corneal thickness\n",
        "    \"escc\",  # Abbreviation for esophageal squamous cell carcinoma\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cfef3be-698f-4792-b7c3-46fac945e7f5",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "8cfef3be-698f-4792-b7c3-46fac945e7f5"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "\n",
        "Solution_1_3\n",
        "    \n",
        "</div>\n",
        "\n",
        "_Points:_ 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "44097c5d-97a0-450e-af88-73c9a4c90c94",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44097c5d-97a0-450e-af88-73c9a4c90c94",
        "outputId": "ba4b2bca-d14e-4197-b23a-8219ac4cdbda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "covididiot False\n",
            "fomo False\n",
            "frenemies True\n",
            "anthropause False\n",
            "photobomb False\n",
            "selfie False\n",
            "pxg False\n",
            "pacg False\n",
            "cct True\n",
            "escc True\n"
          ]
        }
      ],
      "source": [
        "for word in test_words:\n",
        "    print(word, word in glove_wiki_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2155dbe-979f-4e4d-bd4c-04d2a5f0be20",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "a2155dbe-979f-4e4d-bd4c-04d2a5f0be20"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06ea8f10-8bfb-4698-b76c-60f5f8256d5d",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "06ea8f10-8bfb-4698-b76c-60f5f8256d5d"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "### 1.4 Stereotypes and biases in embeddings\n",
        "rubric={points}\n",
        "\n",
        "Word vectors contain lots of useful information. But they also contain stereotypes and biases of the texts they were trained on. In the lecture, we saw an example of gender bias in Google News word embeddings. Here we are using pre-trained embeddings trained on Wikipedia data.\n",
        "\n",
        "**Your tasks:**\n",
        "\n",
        "1. Explore whether there are any worrisome biases or stereotypes present in these embeddings by trying out at least 4 examples. You can use the following two methods or other methods of your choice to explore this.\n",
        "    - the `analogy` function below which gives word analogies (an example shown below)\n",
        "    - [similarity](https://radimrehurek.com/gensim/models/keyedvectors.html?highlight=similarity#gensim.models.keyedvectors.KeyedVectors.similarity) or [distance](https://radimrehurek.com/gensim/models/keyedvectors.html?highlight=distance#gensim.models.keyedvectors.KeyedVectors.distances) methods (an example is shown below)\n",
        "\n",
        "> Note that most of the recent embeddings are de-biased. But you might still observe some biases in them. Also, not all stereotypes present in pre-trained embeddings are necessarily bad. But you should be aware of them when you use them in your models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2a90c0cd-7cf2-4f82-a617-9a87c526281d",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "2a90c0cd-7cf2-4f82-a617-9a87c526281d"
      },
      "outputs": [],
      "source": [
        "def analogy(word1, word2, word3, model=glove_wiki_vectors):\n",
        "    \"\"\"\n",
        "    Returns analogy word using the given model.\n",
        "\n",
        "    Parameters\n",
        "    --------------\n",
        "    word1 : (str)\n",
        "        word1 in the analogy relation\n",
        "    word2 : (str)\n",
        "        word2 in the analogy relation\n",
        "    word3 : (str)\n",
        "        word3 in the analogy relation\n",
        "    model :\n",
        "        word embedding model\n",
        "\n",
        "    Returns\n",
        "    ---------------\n",
        "        pd.dataframe\n",
        "    \"\"\"\n",
        "    print(\"%s : %s :: %s : ?\" % (word1, word2, word3))\n",
        "    sim_words = model.most_similar(positive=[word3, word2], negative=[word1])\n",
        "    return pd.DataFrame(sim_words, columns=[\"Analogy word\", \"Score\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8aaeec14-64c1-4226-b60f-849489077ddd",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "8aaeec14-64c1-4226-b60f-849489077ddd"
      },
      "source": [
        "Examples of using analogy to explore biases and stereotypes.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e914a9fa-e1e9-4182-a82d-41737020e44f",
      "metadata": {
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "e914a9fa-e1e9-4182-a82d-41737020e44f",
        "outputId": "3b2d168d-adc4-42c5-b486-051bdd2c8828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "man : doctor :: woman : ?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Analogy word     Score\n",
              "0        nurse  0.773523\n",
              "1    physician  0.718943\n",
              "2      doctors  0.682433\n",
              "3      patient  0.675068\n",
              "4      dentist  0.672603\n",
              "5     pregnant  0.664246\n",
              "6      medical  0.652045\n",
              "7      nursing  0.645348\n",
              "8       mother  0.639333\n",
              "9     hospital  0.638750"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-245bad2d-6c99-48b5-b753-136bd862ad2e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Analogy word</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nurse</td>\n",
              "      <td>0.773523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>physician</td>\n",
              "      <td>0.718943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>doctors</td>\n",
              "      <td>0.682433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>patient</td>\n",
              "      <td>0.675068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dentist</td>\n",
              "      <td>0.672603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>pregnant</td>\n",
              "      <td>0.664246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>medical</td>\n",
              "      <td>0.652045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>nursing</td>\n",
              "      <td>0.645348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>mother</td>\n",
              "      <td>0.639333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>hospital</td>\n",
              "      <td>0.638750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-245bad2d-6c99-48b5-b753-136bd862ad2e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-245bad2d-6c99-48b5-b753-136bd862ad2e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-245bad2d-6c99-48b5-b753-136bd862ad2e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "analogy(\"man\", \"doctor\", \"woman\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "fceb0128-3c9b-4674-ae40-da3d80f3f00c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fceb0128-3c9b-4674-ae40-da3d80f3f00c",
        "outputId": "aacb6124-a7ef-4b82-d5bf-726f5b7c823c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(0.14283238)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "glove_wiki_vectors.similarity(\"aboriginal\", \"success\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "774cb08e-95bc-458b-bc78-ee3fcf2b2f7a",
      "metadata": {
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "774cb08e-95bc-458b-bc78-ee3fcf2b2f7a",
        "outputId": "c4da7333-d831-41e7-fc9a-f17b05693e48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(0.35182396)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "glove_wiki_vectors.similarity(\"white\", \"success\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b55bef6d-9a57-41a4-8a83-a65d7bc07783",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "b55bef6d-9a57-41a4-8a83-a65d7bc07783"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "\n",
        "Solution_1_4\n",
        "    \n",
        "</div>\n",
        "\n",
        "_Points:_ 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a227771e-f8b7-4bad-9881-eb5528f10e9e",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a227771e-f8b7-4bad-9881-eb5528f10e9e",
        "outputId": "6ff04a13-812a-44d5-8d36-cb38733e6db0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(0.36956844)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "glove_wiki_vectors.similarity(\"indian\", \"violence\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "6025b7c9-5ffd-4076-8d44-0440d01efe69",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6025b7c9-5ffd-4076-8d44-0440d01efe69",
        "outputId": "851d8213-b6e8-4683-a4aa-4b877124a583"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(0.18276742)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "glove_wiki_vectors.similarity(\"canadian\", \"violence\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "deaa74e9-858e-4b28-a7a8-6b6b522c1ef6",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "deaa74e9-858e-4b28-a7a8-6b6b522c1ef6",
        "outputId": "926bf384-86aa-46e8-c0cd-0d440d88834e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "white : rich :: coloured : ?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Analogy word     Score\n",
              "0       richly  0.565491\n",
              "1      mineral  0.564086\n",
              "2       richer  0.544013\n",
              "3     abundant  0.528304\n",
              "4      fertile  0.524897\n",
              "5      diverse  0.508858\n",
              "6     textures  0.498944\n",
              "7     textured  0.497468\n",
              "8   fabulously  0.488432\n",
              "9     alluvial  0.488141"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0751bb6e-f580-444e-ae16-b74d3af603dd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Analogy word</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>richly</td>\n",
              "      <td>0.565491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mineral</td>\n",
              "      <td>0.564086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>richer</td>\n",
              "      <td>0.544013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abundant</td>\n",
              "      <td>0.528304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fertile</td>\n",
              "      <td>0.524897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>diverse</td>\n",
              "      <td>0.508858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>textures</td>\n",
              "      <td>0.498944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>textured</td>\n",
              "      <td>0.497468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>fabulously</td>\n",
              "      <td>0.488432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>alluvial</td>\n",
              "      <td>0.488141</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0751bb6e-f580-444e-ae16-b74d3af603dd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0751bb6e-f580-444e-ae16-b74d3af603dd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0751bb6e-f580-444e-ae16-b74d3af603dd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "analogy(\"white\", \"rich\", \"coloured\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "95e306e7-26f3-4367-8935-0be49b86be56",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "95e306e7-26f3-4367-8935-0be49b86be56",
        "outputId": "920d16ab-2304-401c-d9f0-2566507830d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "men : competent :: blondes : ?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Analogy word     Score\n",
              "0   unadventurous  0.617484\n",
              "1     fair-minded  0.587928\n",
              "2       spineless  0.549455\n",
              "3     cool-headed  0.547146\n",
              "4    self-assured  0.543766\n",
              "5      hardheaded  0.541290\n",
              "6     venturesome  0.533579\n",
              "7   incorruptible  0.533527\n",
              "8  unclassifiable  0.531733\n",
              "9       maladroit  0.531262"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35aaf95f-da76-4961-a3ab-6531269735ab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Analogy word</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>unadventurous</td>\n",
              "      <td>0.617484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fair-minded</td>\n",
              "      <td>0.587928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spineless</td>\n",
              "      <td>0.549455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cool-headed</td>\n",
              "      <td>0.547146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>self-assured</td>\n",
              "      <td>0.543766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>hardheaded</td>\n",
              "      <td>0.541290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>venturesome</td>\n",
              "      <td>0.533579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>incorruptible</td>\n",
              "      <td>0.533527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>unclassifiable</td>\n",
              "      <td>0.531733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>maladroit</td>\n",
              "      <td>0.531262</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35aaf95f-da76-4961-a3ab-6531269735ab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-35aaf95f-da76-4961-a3ab-6531269735ab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-35aaf95f-da76-4961-a3ab-6531269735ab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "analogy(\"men\", \"competent\", \"blondes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19f04b87-5fa0-4eb4-bb50-cb21aa7ffd1c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "19f04b87-5fa0-4eb4-bb50-cb21aa7ffd1c"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f474b6ac-25f3-45f1-97db-bfadf71d9f80",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "f474b6ac-25f3-45f1-97db-bfadf71d9f80"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "### 1.5 Discussion\n",
        "rubric={points}\n",
        "\n",
        "**Your tasks:**\n",
        "1. Discuss your observations from 1.4. Are there any worrisome biases in these embeddings trained on Wikipedia?   \n",
        "2. Give an example of how using embeddings with biases could cause harm in the real world."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36e95ea8-80c0-4184-8b89-1fa1581404f1",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "36e95ea8-80c0-4184-8b89-1fa1581404f1"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "\n",
        "Solution_1_5\n",
        "    \n",
        "</div>\n",
        "\n",
        "_Points:_ 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de9c42f8",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "de9c42f8"
      },
      "source": [
        "1. The only one that wasn't concerning was the third example of \"white, rich, and coloured\". The first two examples were worrisome because the score for the similarity between violence and Indians was double the score for the similarity between Canadians and violence. The last example only had a few concerning similar words, such as spineless and unadventurous, however there are positive adjectives for them as well.\n",
        "\n",
        "2. When used by LLMs such as ChatGPT, they may perpetuate these stereotypes and biases to a user who may not have the ability to understand that stereotypes can be false.\n",
        "For example, younger kids have access to ChatGPT before having a full picture of how the world really is, so they may trust that everything that ChatGPT says is true. Given this, if, for example, that user asks ChatGPT about coloured people or about white people, ChatGPT may associate the word violence to coloured people more than they would for white people, and the kid may then also have a stereotype in their head that coloured people are more violent because they have no one supervising the information they learn from ChatGPT(using violence as an example since I used that word in 1.4, but violence can be substituted with another negative stereotype)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "161a6ab6-62ef-4fdd-ba0d-5e7e920154a3",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "161a6ab6-62ef-4fdd-ba0d-5e7e920154a3"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67cb13f7-e08c-4f8d-86c9-b1602cc8a5b4",
      "metadata": {
        "id": "67cb13f7-e08c-4f8d-86c9-b1602cc8a5b4"
      },
      "source": [
        "## Exercise 2: Topic modeling\n",
        "\n",
        "The goal of topic modeling is discovering high-level themes in a large collection of texts.\n",
        "\n",
        "In this homework, you will explore topics in [the 20 newsgroups text dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html) using `scikit-learn`'s `LatentDirichletAllocation` (LDA) model.\n",
        "\n",
        "Usually, topic modeling is used for discovering abstract \"topics\" that occur in a collection of documents when you do not know the actual topics present in the documents. But 20 newsgroups text dataset is labeled with categories (e.g., sports, hardware, religion), and you will be able to cross-check the topics discovered by your model with these available topics.\n",
        "\n",
        "The starter code below loads the train and test portion of the data and convert the train portion into a pandas DataFrame. For speed, we will only consider documents with the following 8 categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "327ca91e-cf57-4481-b4cc-46c29a9849a3",
      "metadata": {
        "id": "327ca91e-cf57-4481-b4cc-46c29a9849a3"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "9afa3b30-7f32-48ec-8291-69c964a38c74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9afa3b30-7f32-48ec-8291-69c964a38c74",
        "outputId": "efa0ba75-7da9-4550-bdc4-53d096fc9df9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  target  \\\n",
              "0     You know, I was reading 18 U.S.C. 922 and some...       6   \n",
              "1     \\n\\n\\nIt's not a bad question: I don't have an...       1   \n",
              "2     \\nActuallay I don't, but on the other hand I d...       1   \n",
              "3     The following problem is really bugging me,\\na...       2   \n",
              "4     \\n\\n  This is the latest from UPI \\n\\n     For...       7   \n",
              "...                                                 ...     ...   \n",
              "4558  Hi Everyone ::\\n\\nI am  looking for  some soft...       1   \n",
              "4559  Archive-name: x-faq/part3\\nLast-modified: 1993...       2   \n",
              "4560  \\nThat's nice, but it doesn't answer the quest...       6   \n",
              "4561  Hi,\\n     I just got myself a Gateway 4DX-33V ...       2   \n",
              "4562  \\n\\n[h] \\tThe Armenians in Nagarno-Karabagh ar...       7   \n",
              "\n",
              "                target_name  \n",
              "0        talk.politics.guns  \n",
              "1             comp.graphics  \n",
              "2             comp.graphics  \n",
              "3            comp.windows.x  \n",
              "4     talk.politics.mideast  \n",
              "...                     ...  \n",
              "4558          comp.graphics  \n",
              "4559         comp.windows.x  \n",
              "4560     talk.politics.guns  \n",
              "4561         comp.windows.x  \n",
              "4562  talk.politics.mideast  \n",
              "\n",
              "[4563 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6a554c7-846d-4977-b406-4813586ff132\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>target_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>You know, I was reading 18 U.S.C. 922 and some...</td>\n",
              "      <td>6</td>\n",
              "      <td>talk.politics.guns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n\\n\\nIt's not a bad question: I don't have an...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nActuallay I don't, but on the other hand I d...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The following problem is really bugging me,\\na...</td>\n",
              "      <td>2</td>\n",
              "      <td>comp.windows.x</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\n\\n  This is the latest from UPI \\n\\n     For...</td>\n",
              "      <td>7</td>\n",
              "      <td>talk.politics.mideast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4558</th>\n",
              "      <td>Hi Everyone ::\\n\\nI am  looking for  some soft...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4559</th>\n",
              "      <td>Archive-name: x-faq/part3\\nLast-modified: 1993...</td>\n",
              "      <td>2</td>\n",
              "      <td>comp.windows.x</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4560</th>\n",
              "      <td>\\nThat's nice, but it doesn't answer the quest...</td>\n",
              "      <td>6</td>\n",
              "      <td>talk.politics.guns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4561</th>\n",
              "      <td>Hi,\\n     I just got myself a Gateway 4DX-33V ...</td>\n",
              "      <td>2</td>\n",
              "      <td>comp.windows.x</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4562</th>\n",
              "      <td>\\n\\n[h] \\tThe Armenians in Nagarno-Karabagh ar...</td>\n",
              "      <td>7</td>\n",
              "      <td>talk.politics.mideast</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4563 rows  3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6a554c7-846d-4977-b406-4813586ff132')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e6a554c7-846d-4977-b406-4813586ff132 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e6a554c7-846d-4977-b406-4813586ff132');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "cats = [\n",
        "    \"rec.sport.hockey\",\n",
        "    \"rec.sport.baseball\",\n",
        "    \"soc.religion.christian\",\n",
        "    \"alt.atheism\",\n",
        "    \"comp.graphics\",\n",
        "    \"comp.windows.x\",\n",
        "    \"talk.politics.mideast\",\n",
        "    \"talk.politics.guns\",\n",
        "]  # We'll only consider these categories out of 20 categories for speed.\n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(\n",
        "    subset=\"train\", remove=(\"headers\", \"footers\", \"quotes\"), categories=cats\n",
        ")\n",
        "X_news_train, y_news_train = newsgroups_train.data, newsgroups_train.target\n",
        "df = pd.DataFrame(X_news_train, columns=[\"text\"])\n",
        "df[\"target\"] = y_news_train\n",
        "df[\"target_name\"] = [\n",
        "    newsgroups_train.target_names[target] for target in newsgroups_train.target\n",
        "]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "8095c853-d4d5-49a3-bda0-129ffd2f690b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8095c853-d4d5-49a3-bda0-129ffd2f690b",
        "outputId": "61be8514-36cb-4e9c-c368-262500dccb74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.windows.x',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "newsgroups_train.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db9cdcfc-7545-4a40-a9b3-34b58bb38365",
      "metadata": {
        "id": "db9cdcfc-7545-4a40-a9b3-34b58bb38365"
      },
      "source": [
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e21b066-8de6-42a7-8e4e-097fd8727367",
      "metadata": {
        "deletable": false,
        "editable": false,
        "tags": [],
        "id": "0e21b066-8de6-42a7-8e4e-097fd8727367"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "### 2.1 Preprocessing using [spaCy](https://spacy.io/)\n",
        "rubric={points}\n",
        "\n",
        "Preprocessing is a crucial step before carrying out topic modeling and it markedly affects topic modeling results. In this exercise, you'll prepare the data using [spaCy](https://spacy.io/) for topic modeling.\n",
        "\n",
        "**Your tasks:**\n",
        "\n",
        "- Write code using [spaCy](https://spacy.io/) to preprocess the `text` column in the given dataframe `df` and save the processed text in a new column called `text_pp` within the same dataframe.\n",
        "\n",
        "If you do not have spaCy in your course environment, you'll have to [install it](https://spacy.io/usage) and download the pretrained model en_core_web_md.\n",
        "\n",
        "`python -m spacy download en_core_web_md`\n",
        "\n",
        "\n",
        "Note that there is no such thing as \"perfect\" preprocessing. You'll have to make your own judgments and decisions on which tokens are likely to be more informative for the given task. Some common text preprocessing steps for topic modeling include:\n",
        "- getting rid of slashes, new-line characters, or any other non-informative characters\n",
        "- sentence segmentation and tokenization      \n",
        "- replacing urls, email addresses, or numbers with generic tokens such as \"URL\",  \"EMAIL\", \"NUM\".\n",
        "- getting rid of other fairly unique tokens which are not going to help us in topic modeling  \n",
        "- excluding stopwords and punctuation\n",
        "- lemmatization\n",
        "\n",
        "\n",
        "> Check out [these available attributes](https://spacy.io/api/token#attributes) for `token` in spaCy which might help you with preprocessing.\n",
        "\n",
        "> You can also get rid of words with specific POS tags. [Here](https://universaldependencies.org/u/pos/) is the list of part-of-speech tags used in spaCy.\n",
        "\n",
        "> You may have to use regex to clean text before passing it to spaCy. Also, you might have to go back and forth between preprocessing in this exercise and and topic modeling in Exercise 2 before finalizing preprocessing steps.\n",
        "\n",
        "> Note that preprocessing the corpus might take some time. So here are a couple of suggestions: 1) During the debugging phase, work on a smaller subset of the data. 2) Once you finalize the preprocessing part, you might want to save the preprocessed data in a CSV and work with this CSV so that you don't run the preprocessing part every time you run the notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9ICXbZmX6El",
        "outputId": "3c642e56-e2c4-46f7-9498-7f655db1fba0"
      },
      "id": "t9ICXbZmX6El",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.8)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (1.17.3)\n",
            "Collecting en-core-web-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "6816e7a3-d6d4-4bef-81f4-9b4fdf638175",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "6816e7a3-d6d4-4bef-81f4-9b4fdf638175"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_md\", disable=[\"parser\", \"ner\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0036dbe6-2353-4c5a-80bf-2b884a170a29",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "0036dbe6-2353-4c5a-80bf-2b884a170a29"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "\n",
        "Solution_2_1\n",
        "    \n",
        "</div>\n",
        "\n",
        "_Points:_ 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "8be7c802-d10b-4929-9664-34274299e884",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "8be7c802-d10b-4929-9664-34274299e884"
      },
      "outputs": [],
      "source": [
        "#pulled from lecture 17, and added a few more if statements above such as the url, num, and punctuation\n",
        "import re # I didn't know what library to use for regex, so I asked chatgpt what library I can use for it, and it told me to import re. I then looked up documentation for re\n",
        "def regex(token):\n",
        "  token = re.sub(r\"\\n+\", \" \", token)\n",
        "  token = re.sub(r\"[^A-Za-z0-9\\s]\", \" \", token)\n",
        "  token = re.sub(r\"\\s+\", \" \", token)\n",
        "  return token.strip()\n",
        "\n",
        "def preprocess(\n",
        "    doc,\n",
        "    min_token_len=2,\n",
        "    irrelevant_pos=[\"ADV\", \"PRON\", \"CCONJ\", \"PUNCT\", \"PART\", \"DET\", \"ADP\", \"SPACE\"],\n",
        "):\n",
        "    clean_text = []\n",
        "\n",
        "    for token in doc:\n",
        "      if token.lower_ == \"n't\":\n",
        "            clean_tokens.append(\"not\")\n",
        "            continue\n",
        "      if token.is_space or token.is_punct:\n",
        "            continue\n",
        "      if (token.like_url):\n",
        "            clean_text.append(\"URL\")\n",
        "            continue\n",
        "      if (token.like_email):\n",
        "            clean_text.append(\"EMAIL\")\n",
        "            continue\n",
        "      if (token.like_num):\n",
        "            clean_text.append(\"NUM\")\n",
        "            continue\n",
        "      if (\n",
        "          token.is_stop == False  # Check if it's not a stopword\n",
        "          and len(token) > min_token_len  # Check if the word meets minimum threshold\n",
        "          and token.pos_ not in irrelevant_pos):  # Check if the POS is in the acceptable POS tags\n",
        "            lemma = token.lemma_  # Take the lemma of the word\n",
        "            clean_text.append(lemma.lower())\n",
        "    return \" \".join(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "ba75d96d-01dc-4b3b-b222-67c63b5fd0c5",
      "metadata": {
        "metadata": {
          "tags": [
            "otter_ignore"
          ]
        },
        "tags": [
          "otter_answer_cell"
        ],
        "id": "ba75d96d-01dc-4b3b-b222-67c63b5fd0c5"
      },
      "outputs": [],
      "source": [
        "df[\"clean\"] = df[\"text\"].apply(regex)\n",
        "df[\"preprocessed\"] = [preprocess(doc) for doc in nlp.pipe(df[\"clean\"])]\n",
        "df.to_csv(\"preprocessed.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "0782a094-bd30-4e80-9678-8f1197ca6a28",
      "metadata": {
        "metadata": {
          "tags": [
            "otter_ignore"
          ]
        },
        "tags": [
          "otter_answer_cell"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0782a094-bd30-4e80-9678-8f1197ca6a28",
        "outputId": "7d9cdf76-e07e-4e7d-e11a-5c3ab72965fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "3c2b633b-6601-4b83-8668-800a99d3ba20",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "3c2b633b-6601-4b83-8668-800a99d3ba20",
        "outputId": "ea50ffad-afbd-4865-ffa2-c535a2fce3e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target  \\\n",
              "2  \\nActuallay I don't, but on the other hand I d...       1   \n",
              "3  The following problem is really bugging me,\\na...       2   \n",
              "4  \\n\\n  This is the latest from UPI \\n\\n     For...       7   \n",
              "5  Hi,\\n   I'd like to subscribe to Leadership Ma...       5   \n",
              "\n",
              "              target_name                                              clean  \\\n",
              "2           comp.graphics  Actuallay I don t but on the other hand I don ...   \n",
              "3          comp.windows.x  The following problem is really bugging me and...   \n",
              "4   talk.politics.mideast  This is the latest from UPI Foreign Ministry s...   \n",
              "5  soc.religion.christian  Hi I d like to subscribe to Leadership Magazin...   \n",
              "\n",
              "                                        preprocessed  \n",
              "2  actuallay don hand don support idea have NUM n...  \n",
              "3  follow problem bug appreciate help create NUM ...  \n",
              "4  late upi foreign ministry spokesman ferhat ata...  \n",
              "5  like subscribe leadership magazine wonder NUM ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0ce9e33-abc2-47d1-b2a7-52874f702d8d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>target_name</th>\n",
              "      <th>clean</th>\n",
              "      <th>preprocessed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nActuallay I don't, but on the other hand I d...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "      <td>Actuallay I don t but on the other hand I don ...</td>\n",
              "      <td>actuallay don hand don support idea have NUM n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The following problem is really bugging me,\\na...</td>\n",
              "      <td>2</td>\n",
              "      <td>comp.windows.x</td>\n",
              "      <td>The following problem is really bugging me and...</td>\n",
              "      <td>follow problem bug appreciate help create NUM ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\n\\n  This is the latest from UPI \\n\\n     For...</td>\n",
              "      <td>7</td>\n",
              "      <td>talk.politics.mideast</td>\n",
              "      <td>This is the latest from UPI Foreign Ministry s...</td>\n",
              "      <td>late upi foreign ministry spokesman ferhat ata...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Hi,\\n   I'd like to subscribe to Leadership Ma...</td>\n",
              "      <td>5</td>\n",
              "      <td>soc.religion.christian</td>\n",
              "      <td>Hi I d like to subscribe to Leadership Magazin...</td>\n",
              "      <td>like subscribe leadership magazine wonder NUM ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0ce9e33-abc2-47d1-b2a7-52874f702d8d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0ce9e33-abc2-47d1-b2a7-52874f702d8d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0ce9e33-abc2-47d1-b2a7-52874f702d8d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "df.iloc[2:6]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94bbad26-84c1-41ed-8201-0843924b3166",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "94bbad26-84c1-41ed-8201-0843924b3166"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f080f91c-6801-4b89-9fbc-1b574b09915c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "f080f91c-6801-4b89-9fbc-1b574b09915c"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "### 2.2 Build a topic model using sklearn's LatentDirichletAllocation\n",
        "rubric={points}\n",
        "\n",
        "**Your tasks:**\n",
        "\n",
        "1. Build LDA models on the preprocessed data using using [sklearn's `LatentDirichletAllocation`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html) and random state 42. Experiment with a few values for the number of topics (`n_components`). Pick a reasonable number for the number of topics and briefly justify your choice."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e472711-3c92-4b82-a31d-5d4bf55dbf2a",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "1e472711-3c92-4b82-a31d-5d4bf55dbf2a"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "\n",
        "Solution_2_2\n",
        "    \n",
        "</div>\n",
        "\n",
        "_Points:_ 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d72457e",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "7d72457e"
      },
      "source": [
        "I picked 8 because we are using 8 out of the 20 categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "88908be8-85df-40bf-9d6d-0b48948a7137",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "88908be8-85df-40bf-9d6d-0b48948a7137"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "preprocessed_csv = pd.read_csv(\"preprocessed.csv\")\n",
        "vec = CountVectorizer(stop_words='english')\n",
        "X = vec.fit_transform(df[\"preprocessed\"])\n",
        "\n",
        "n_topics = 8\n",
        "lda = LatentDirichletAllocation(\n",
        "    n_components=n_topics, learning_method=\"batch\", max_iter=10, random_state=42\n",
        ")\n",
        "document_topics = lda.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "bed16e6f-2706-463e-80cc-c64d2b75a296",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bed16e6f-2706-463e-80cc-c64d2b75a296",
        "outputId": "ebf3e01a-419f-4d06-d5fd-4b034ecad1f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.15818247e-03, 2.15922312e-03, 2.15730090e-03, ...,\n",
              "        8.25029862e-01, 2.15761149e-03, 1.62020166e-01],\n",
              "       [8.72354922e-01, 1.50832848e-03, 1.50812977e-03, ...,\n",
              "        1.50832514e-03, 1.50785812e-03, 1.50986958e-03],\n",
              "       [4.27790859e-01, 1.92662859e-03, 1.92553999e-03, ...,\n",
              "        1.92558809e-03, 1.92608033e-03, 5.60654000e-01],\n",
              "       ...,\n",
              "       [2.40614917e-03, 2.40931943e-03, 2.40633544e-03, ...,\n",
              "        8.74530265e-01, 2.40527021e-03, 1.11025631e-01],\n",
              "       [6.03005589e-01, 3.20663185e-03, 3.20583550e-03, ...,\n",
              "        3.20875137e-03, 2.39977360e-01, 3.20977255e-03],\n",
              "       [3.78066028e-04, 3.78102418e-04, 3.78047146e-04, ...,\n",
              "        9.26208312e-01, 7.15234685e-02, 3.78182163e-04]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "document_topics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e1afbdb-b419-4d17-a7fa-0dfd9e618f15",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4e1afbdb-b419-4d17-a7fa-0dfd9e618f15"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20f4ff43-188c-4d9a-8404-691cd563dd9a",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "20f4ff43-188c-4d9a-8404-691cd563dd9a"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "### 2.3 Exploring word topic association\n",
        "rubric={points}\n",
        "\n",
        "**Your tasks:**\n",
        "1. For the number of topics you picked in the previous exercise, show top 10 words for each of your topics and suggest labels for each of the topics (similar to how we came up with labels \"health and nutrition\", \"fashion\", and \"machine learning\" in the toy example we saw in class).\n",
        "\n",
        "> If your topics do not make much sense, you might have to go back to preprocessing in Exercise 2.1, improve it, and train your LDA model again."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9dbe9de-c9d9-41a1-bf5a-10220ce6fa38",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "c9dbe9de-c9d9-41a1-bf5a-10220ce6fa38"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "\n",
        "Solution_2_3\n",
        "    \n",
        "</div>\n",
        "\n",
        "_Points:_ 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29e1644d",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "29e1644d"
      },
      "source": [
        "_Type your answer here, replacing this text._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "967136f3-5746-4568-8d2d-d48c4d3be36c",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "967136f3-5746-4568-8d2d-d48c4d3be36c",
        "outputId": "8a67bd1b-19a0-406b-aa4d-a7bf4ec065cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['000000e5', '00000ee5', '000010af', ..., 'zyxel', 'zzzzzz',\n",
              "       'zzzzzzt'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
        "feature_names = np.array(vec.get_feature_names_out())\n",
        "feature_names"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mglearn"
      ],
      "metadata": {
        "id": "Cj8hxCHAfz1y",
        "outputId": "c34a56cc-6c5f-4611-ada4-c8755fc3d5df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Cj8hxCHAfz1y",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mglearn in /usr/local/lib/python3.12/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from mglearn) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mglearn) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from mglearn) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from mglearn) (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from mglearn) (11.3.0)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from mglearn) (0.12.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (from mglearn) (2.37.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from mglearn) (1.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mglearn) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mglearn) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mglearn) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mglearn) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mglearn) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mglearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->mglearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->mglearn) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->mglearn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->mglearn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mglearn) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "18caef39-4161-438b-90f2-99337f39dcd9",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18caef39-4161-438b-90f2-99337f39dcd9",
        "outputId": "51ce2ee7-55f5-47d2-ce16-9fdcea9b2f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
            "--------      --------      --------      --------      --------      \n",
            "num           num           israel        num           right         \n",
            "window        god           jews          game          militia       \n",
            "image         believe       israeli       team          state         \n",
            "use           jesus         jewish        play          people        \n",
            "file          people        arab          season        team          \n",
            "program       know          state         win           num           \n",
            "display       think         people        year          think         \n",
            "widget        say           right         period        define        \n",
            "color         church        war           player        know          \n",
            "run           question      country       league        don           \n",
            "\n",
            "\n",
            "topic 5       topic 6       topic 7       \n",
            "--------      --------      --------      \n",
            "num           num           num           \n",
            "gun           file          think         \n",
            "people        edu           know          \n",
            "weapon        turkish       don           \n",
            "law           output        say           \n",
            "kill          include       people        \n",
            "say           entry         come          \n",
            "firearm       armenian      time          \n",
            "government    program       good          \n",
            "crime         source        year          \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import mglearn\n",
        "\n",
        "mglearn.tools.print_topics(\n",
        "    topics=range(8),\n",
        "    feature_names=feature_names,\n",
        "    sorting=sorting,\n",
        "    topics_per_chunk=5,\n",
        "    n_words=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic 0 would be UI/grapics on a PC. Topic 1 would be sermons (talking about religion, asking questions about it, etc.), topic 2 would be Middle Eastern Politics, topic 3 would be competitions, topic 4 would be military, topic 5 would be government & law, topic 6 would be education (basing it off edu, however the outliers would be turkish and armenian),education topic 7 would be future events (has time/arrival words)"
      ],
      "metadata": {
        "id": "J6uFdIRngqBX"
      },
      "id": "J6uFdIRngqBX"
    },
    {
      "cell_type": "markdown",
      "id": "7b4cbbb9-1057-43ef-ac63-842e3e4cb43c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "7b4cbbb9-1057-43ef-ac63-842e3e4cb43c"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d53117b-897c-4eba-b1bd-dfedcb3d35ff",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "1d53117b-897c-4eba-b1bd-dfedcb3d35ff"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "### 2.4 Exploring document topic association\n",
        "rubric={points}\n",
        "\n",
        "**Your tasks:**\n",
        "1. Show the document topic assignment of the first five documents from `df`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12934a67-c48d-4c42-a856-248615c6202b",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "12934a67-c48d-4c42-a856-248615c6202b"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "\n",
        "Solution_2_4\n",
        "    \n",
        "</div>\n",
        "\n",
        "_Points:_ 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "1f09783a-5644-46ac-bb2f-d60947a13d21",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f09783a-5644-46ac-bb2f-d60947a13d21",
        "outputId": "671b9462-06d0-438a-973e-3d5c001635bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Government & Law\n",
            "PC UI/grapics\n",
            "Future Events\n",
            "PC UI/grapics\n",
            "Government & Law\n"
          ]
        }
      ],
      "source": [
        "topic_labels = {\n",
        "    0: \"PC UI/grapics\",\n",
        "    1: \"Sermons\",\n",
        "    2: \"Middle Eastern Politics\",\n",
        "    3: \"Competitions\",\n",
        "    4: \"Military\",\n",
        "    5: \"Government & Law\",\n",
        "    6: \"Education\",\n",
        "    7: \"Future Events\"\n",
        "}\n",
        "assigned_topic1 = np.argmax(document_topics[0])\n",
        "assigned_topic2 = np.argmax(document_topics[1])\n",
        "assigned_topic3 = np.argmax(document_topics[2])\n",
        "assigned_topic4 = np.argmax(document_topics[3])\n",
        "assigned_topic5 = np.argmax(document_topics[4])\n",
        "label1 = topic_labels[assigned_topic1]\n",
        "label2 = topic_labels[assigned_topic2]\n",
        "label3 = topic_labels[assigned_topic3]\n",
        "label4 = topic_labels[assigned_topic4]\n",
        "label5 = topic_labels[assigned_topic5]\n",
        "print(label1)\n",
        "print(label2)\n",
        "print(label3)\n",
        "print(label4)\n",
        "print(label5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HzI04Y0ylkAD"
      },
      "id": "HzI04Y0ylkAD",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "51e21cac-5f1a-4480-b683-47c3b41a1199",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "51e21cac-5f1a-4480-b683-47c3b41a1199"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e42685c5-01cb-4495-aae6-f803d6f75172",
      "metadata": {
        "deletable": false,
        "editable": false,
        "tags": [],
        "id": "e42685c5-01cb-4495-aae6-f803d6f75172"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "## Exercise 3: Short answer questions\n",
        "<hr>\n",
        "\n",
        "rubric={points}\n",
        "\n",
        "1. Briefly explain how content-based filtering works in the context of recommender systems.\n",
        "2. Discuss at least two negative consequences of recommender systems.\n",
        "3. What is transfer learning in natural language processing? Briefly explain.     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5Bh1mtffliv4"
      },
      "id": "5Bh1mtffliv4"
    },
    {
      "cell_type": "markdown",
      "id": "01807641-531e-454a-9374-fc8ad04bc30b",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "01807641-531e-454a-9374-fc8ad04bc30b"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "\n",
        "Solution_3\n",
        "    \n",
        "</div>\n",
        "\n",
        "_Points:_ 6"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d9d88ec",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "7d9d88ec"
      },
      "source": [
        "1. Content-based filtering recommends items to a user based on similarity distances between new items/contents and previous items/contents that the user has engaged with. For example, if a user constantly watches action movies, the system will suggest more action movies. Using Netflix as an example, the system may use the genre tags for each movie (ex. titanic may have the genre tag of romance and drama) as features and compare those features with the features of previous items to see if they match (ex. comparing the genre of titanic to the genre of a movie I watched previously like James Bond would give me a low similarity score, so it would not recommend the titanic).\n",
        "\n",
        "2. Filter bubbles/echo chambers (they would get recommendations that strongly echo the previous choices or media they have engaged with. This is especially harmful in social media when people only view content that aligns with their political views and they get no exposure to other opinions, thus limiting their worldview). The second negative consequence is popularity bias, where the same super popular content or products would constantly get recommended to users, while those who are just starting their social media accounts or just opening their businesses may have a hard time getting that initial exposure.\n",
        "\n",
        "3. This is based off my understanding from the Piazza post. For real world tasks, we need complex models that would be very computationally expensive to build from scratch (ex. using chatbots in another language). Instead, we can use models that have already been trained on previously large datasets and reuse it to fit the task we want. In the context of NLPs, examples of this would be the Google News pre-trained embeddings, where they already have a large vocabulary/phrase bank, and we don't have to retrain the model, we can simply just plug in a word and it can give us similar words because it has been pre-trained. Another exmaple would be using sentence embeddings instead of BoW representation, giving us a better result because it was already pre-trained (as opposed to us training a model from scratch using BoW). Essentially, you are transferring the learning a model has gotten from the initial bulk pre-training and applying that learning into your own adaptation of a situation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12929238-7f2c-421e-bb9a-32f0debf0636",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "12929238-7f2c-421e-bb9a-32f0debf0636"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa042f3b-8f45-4548-bb77-fe22ed288e4a",
      "metadata": {
        "id": "fa042f3b-8f45-4548-bb77-fe22ed288e4a"
      },
      "source": [
        "Before submitting your assignment, please make sure you have followed all the instructions in the Submission Instructions section at the top.\n",
        "\n",
        "Here is a quick checklist before submitting:\n",
        "\n",
        "- [ ] Restart kernel, clear outputs, and run all cells from top to bottom.  \n",
        "- [ ] `.ipynb` file runs without errors and contains all outputs.  \n",
        "- [ ] Only `.ipynb` and required output files are uploaded (no extra files).  \n",
        "- [ ] Execution numbers start at **1** and are in order.  \n",
        "- [ ] If `.ipynb` is too large and doesn't render on Gradescope, also upload a PDF/HTML version.  \n",
        "- [ ] Reviewed the [CPSC 330 homework instructions](https://ubc-cs.github.io/cpsc330-2025W1/docs/homework_instructions.html).  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5491f1d3-dd84-4ed2-b2b3-9148ac8df7a5",
      "metadata": {
        "id": "5491f1d3-dd84-4ed2-b2b3-9148ac8df7a5"
      },
      "source": [
        "![](https://github.com/divagandhi/hw7/blob/main/img/eva-well-done.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a0ZK4rUCorYd"
      },
      "id": "a0ZK4rUCorYd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:cpsc330]",
      "language": "python",
      "name": "conda-env-cpsc330-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "otter": {
      "OK_FORMAT": true,
      "tests": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}